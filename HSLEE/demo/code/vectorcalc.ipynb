{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b44869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "# from ffpyplayer.player import MediaPlayer\n",
    "# from mediapipe.python.solutions import hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d71c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x1,y1,x2,y2): # 비교를 위한 거리 계산 함수\n",
    "    return math.sqrt( math.pow(x1-x2,2) + math.pow(y1-y2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b77c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareIndex = [[18,4],[6,8],[10,12],[14,16],[18,20]] # 마디 index 번호\n",
    "hand_open = [False,False,False,False,False] # False로 초기화\n",
    "gesture = [\n",
    "    [False,True,True,False,False,\"Yeah\"],\n",
    "    [True,False,False,False,False,\"Good\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94ced64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mpHands = mp.solutions.hands\n",
    "my_hands = mpHands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cb7e5",
   "metadata": {},
   "source": [
    "# 첫번째 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7813d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.997370151216305\n"
     ]
    }
   ],
   "source": [
    "#control frame rate\n",
    "cap = cv2.VideoCapture('../dance/attention.mp4') # jupyter \n",
    "# cap = cv2.VideoCapture('./sample_dance/videoplayback.mp4') # vs\n",
    "\n",
    "#cap = cv2.VideoCapture('C:/Users/yoond/바탕 화면/00CAPSTONE/Capstone-Design/DAIN/sample_dance/videoplayback.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_counter = 0\n",
    "frameTime = int((1/fps)*1000)  #time of each frame (ms단위, 몇ms당 1frame으로 할지 설정)\n",
    "print(fps)\n",
    "extract_time_by_per_frame = 1 #몇프레임 당 한번 측정할지 조절 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e7ba30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ###start step2 --> 영상 추출\n",
    "# #extract_file = open('DAIN/extractsamples/result.txt','w')\n",
    "# cap = cv2.VideoCapture('../sample_dance/videoplayback.mp4') # jupyter \n",
    "# # cap = cv2.VideoCapture('./sample_dance/videoplayback.mp4') # vs\n",
    "\n",
    "# #cap = cv2.VideoCapture('C:/Users/yoond/바탕 화면/00CAPSTONE/Capstone-Design/DAIN/sample_dance/videoplayback.mp4')\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "\n",
    "result = np.array([]) # 추출된 영상의 전체 넘파이 배열\n",
    "bone_index = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28] # 필요한 관절 번호\n",
    "\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_counter += 1 #increase frame counter\n",
    "\n",
    "        #Recolor image to RGB\n",
    "        if ret:\n",
    "            if frame_counter % extract_time_by_per_frame == 0:\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                #Detection\n",
    "                results = pose.process(image)\n",
    "\n",
    "                #Recolor image RGB to BGR\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                #Extract landmarks\n",
    "                try: #success to extract landmarks\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    \n",
    "                    ret = []\n",
    "                    \n",
    "                    # # 11 12 13 14 15 16 23 24 25 26 27 28\n",
    "                    for i in bone_index: # 필요한 부분의 관절의 정보만\n",
    "                        temp = np.array([landmarks[i].x,landmarks[i].y,landmarks[i].z], float)\n",
    "                        ret = np.append(ret,temp,axis = 0)\n",
    "                        \n",
    "                        \n",
    "#                     for i in range(len(landmarks)):\n",
    "#                         temp = np.array([landmarks[i].x,landmarks[i].y,landmarks[i].z], float)\n",
    "#                         ret = np.append(ret,temp,axis = 0)\n",
    "                    \n",
    "                    #print(ret)\n",
    "                    result = np.append(result,ret,axis=0)\n",
    "                    #print(\"extracting\\n\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        else: #no next frame (end point of video)\n",
    "            break\n",
    "            #Show video on screen\n",
    "        cv2.imshow('dance_file',frame)\n",
    "        \n",
    "        if cv2.waitKey(frameTime) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    #extract_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40d7011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****extract success*****\n",
      "[[ 0.59443653  0.31211594 -0.4140037 ]\n",
      " [ 0.36862716  0.31133595 -0.4822472 ]\n",
      " [ 0.61208123  0.41514966 -0.23890303]\n",
      " [ 0.34927958  0.42163536 -0.38719669]\n",
      " [ 0.62444079  0.50745541 -0.37093556]\n",
      " [ 0.34446967  0.50966877 -0.538957  ]\n",
      " [ 0.54751533  0.49366298  0.01651365]\n",
      " [ 0.42726916  0.49389952 -0.01702734]\n",
      " [ 0.53012538  0.64128828  0.03779041]\n",
      " [ 0.44629905  0.63877809  0.02240073]\n",
      " [ 0.51319945  0.75820625  0.44198593]\n",
      " [ 0.46011201  0.75520265  0.40289661]]\n",
      "(146, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('*****extract success*****')\n",
    "z = result.shape[0]/(len(bone_index)*3)\n",
    "result = np.reshape(result,(int(z),len(bone_index),3)) # frame 수,  tracking좌표 수, xyz \n",
    "print(result[0])\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f417ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2162fe",
   "metadata": {},
   "source": [
    "# body index\n",
    "body_index = [\n",
    "    \n",
    "    [11,13,15], # left arm\n",
    "    [12,14,16], # right arm\n",
    "    [23,25,27], # left leg\n",
    "    [24,26,28], # right leg\n",
    "    \n",
    "    [14,12,24],\n",
    "    [13,11,23],\n",
    "    [23,24,26],\n",
    "    [24,23,25],\n",
    "    \n",
    "]\n",
    "l1 = result[0][11]\n",
    "l2 = result[0][13]\n",
    "l3 = result[0][15]\n",
    "\n",
    "\n",
    "ll1 = l1-l2\n",
    "ll2 = l3-l2\n",
    "\n",
    "innerAB = np.dot(ll1,ll2)\n",
    "AB = np.linalg.norm(ll1) * np.linalg.norm(ll2)\n",
    "angle = np.arccos(innerAB/AB)\n",
    "print(angle) # radian\n",
    "print(angle/np.pi*180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e3806",
   "metadata": {},
   "source": [
    "# 두번째 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080a82a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.997473950110514\n"
     ]
    }
   ],
   "source": [
    "#control frame rate\n",
    "cap = cv2.VideoCapture('../save_user_video/attention_rest.mp4') #('../../HSLEE/demo/dance/sample.mp4') # jupyter \n",
    "# cap = cv2.VideoCapture('./sample_dance/videoplayback.mp4') # vs\n",
    "\n",
    "#cap = cv2.VideoCapture('C:/Users/yoond/바탕 화면/00CAPSTONE/Capstone-Design/DAIN/sample_dance/videoplayback.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_counter = 0\n",
    "frameTime = int((1/fps)*1000)  #time of each frame (ms단위, 몇ms당 1frame으로 할지 설정)\n",
    "print(fps)\n",
    "extract_time_by_per_frame = 1 #몇프레임 당 한번 측정할지 조절 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4735a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###start step2 --> 영상 추출\n",
    "# #extract_file = open('DAIN/extractsamples/result.txt','w')\n",
    "# cap = cv2.VideoCapture('../sample_dance/videoplayback.mp4') # jupyter \n",
    "# # cap = cv2.VideoCapture('./sample_dance/videoplayback.mp4') # vs\n",
    "\n",
    "# #cap = cv2.VideoCapture('C:/Users/yoond/바탕 화면/00CAPSTONE/Capstone-Design/DAIN/sample_dance/videoplayback.mp4')\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "\n",
    "user_video_result = np.array([]) # 추출된 영상의 전체 넘파이 배열\n",
    "\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_counter += 1 #increase frame counter\n",
    "\n",
    "        #Recolor image to RGB\n",
    "        if ret:\n",
    "            if frame_counter % extract_time_by_per_frame == 0:\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                #Detection\n",
    "                results = pose.process(image)\n",
    "\n",
    "                #Recolor image RGB to BGR\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                #Extract landmarks\n",
    "                try: #success to extract landmarks\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    \n",
    "                    ret = []\n",
    "                    \n",
    "                    # # 11 12 13 14 15 16 23 24 25 26 27 28\n",
    "                    for i in bone_index: # 필요한 부분의 관절의 정보만\n",
    "                        temp = np.array([landmarks[i].x,landmarks[i].y,landmarks[i].z], float)\n",
    "                        ret = np.append(ret,temp,axis = 0)\n",
    "                        \n",
    "                        \n",
    "#                     for i in range(len(landmarks)):\n",
    "#                         temp = np.array([landmarks[i].x,landmarks[i].y,landmarks[i].z], float)\n",
    "#                         ret = np.append(ret,temp,axis = 0)\n",
    "                    \n",
    "                    #print(ret)\n",
    "                    user_video_result = np.append(user_video_result,ret,axis=0)\n",
    "                    #print(\"extracting\\n\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        else: #no next frame (end point of video)\n",
    "            break\n",
    "            #Show video on screen\n",
    "        cv2.imshow('dance_file',frame)\n",
    "        \n",
    "        if cv2.waitKey(frameTime) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    #extract_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14430377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****extract success*****\n",
      "[[ 0.59551901  0.30520397 -0.32198745]\n",
      " [ 0.39104757  0.30594528 -0.36191466]\n",
      " [ 0.60711533  0.40118402 -0.19735564]\n",
      " [ 0.37613732  0.4031454  -0.26750457]\n",
      " [ 0.60751474  0.48029205 -0.38648674]\n",
      " [ 0.37011957  0.48156863 -0.4467569 ]\n",
      " [ 0.53668082  0.47034797  0.01123478]\n",
      " [ 0.43525684  0.46816608 -0.0115667 ]\n",
      " [ 0.5300858   0.60044068 -0.01990704]\n",
      " [ 0.45353487  0.59873593 -0.01237494]\n",
      " [ 0.51100743  0.70961845  0.41195133]\n",
      " [ 0.47295794  0.71164304  0.38295519]]\n",
      "(152, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('*****extract success*****')\n",
    "z = user_video_result.shape[0]/(len(bone_index)*3)\n",
    "user_video_result = np.reshape(user_video_result,(int(z),len(bone_index),3)) # frame 수,  tracking좌표 수, xyz \n",
    "print(user_video_result[0])\n",
    "print(user_video_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982e3a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_video_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a2fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "490ec54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_index = [\n",
    "    [0,2,4], # left arm\n",
    "    [1,3,4], # right arm\n",
    "    [6,8,10], # left leg\n",
    "    [7,9,11], # right leg\n",
    "\n",
    "    [3,1,7], # right shoulder\n",
    "    [2,0,6], # left shoulder\n",
    "    [6,7,9], # right pelvis\n",
    "    [7,6,8], # left pelvis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c75b8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "# user_video_result = result # 녹화된 비디오\n",
    "\n",
    "\n",
    "# 프레임 수가 작은 것을 기준으로 \n",
    "length = len(result)\n",
    "print(length)\n",
    "\n",
    "if( len(result) >= len(user_video_result)):\n",
    "    length = len(user_video_result)\n",
    "    print(len(user_video_result))\n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d1761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c15df678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 226\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4302565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뒤에서부터 비교하기\n",
    "a = len(result) # 146\n",
    "b = len(user_video_result) # 226\n",
    "\n",
    "# 영상 짧아도 무조건 b가 유저 영상\n",
    "# 대신 짧은 값을 length로 가지고 있으니 그걸 가지고 하면 될 듯함\n",
    "# if( a < b ):\n",
    "#     b,a = a,b\n",
    "\n",
    "# 타임스탬프 체크용 카운터\n",
    "time_counter = 0\n",
    "\n",
    "txt = open('../coordinates/comment.txt', 'w')\n",
    "    \n",
    "total_point = 0 # 총 포인트\n",
    "frame_point = 0 # 프레임에서 체크한 포인트\n",
    "\n",
    "joint_counter = np.zeros(8) # 틀린 프레임 누적하면서 어느 부분이 많이 틀렸는지 카운트\n",
    "\n",
    "for n in range(b - 1, b - 1 - length , -1):\n",
    "#     print(\"new frame\")\n",
    "\n",
    "    frame_point = 0\n",
    "    joint_index = 0\n",
    "        \n",
    "    for index in body_index:\n",
    "        l1 = result[n+(a-b)][index[0]]\n",
    "        l2 = result[n+(a-b)][index[1]]\n",
    "        l3 = result[n+(a-b)][index[2]]\n",
    "\n",
    "        ll1 = l1-l2\n",
    "        ll2 = l3-l2\n",
    "        \n",
    "        innerREAL = np.dot(ll1,ll2)\n",
    "        REAL = np.linalg.norm(ll1) * np.linalg.norm(ll2)\n",
    "        angleREAL = np.arccos(innerREAL/REAL)/np.pi*180\n",
    "        #print(angleREAL/np.pi*180)\n",
    "\n",
    "\n",
    "        u1 = user_video_result[n][index[0]]\n",
    "        u2 = user_video_result[n][index[1]]\n",
    "        u3 = user_video_result[n][index[2]]\n",
    "\n",
    "        uu1 = u1-u2\n",
    "        uu2 = u3-u2\n",
    "        \n",
    "        innerUSER = np.dot(uu1,uu2)\n",
    "        USER = np.linalg.norm(uu1) * np.linalg.norm(uu2)\n",
    "        angleUSER = np.arccos(innerUSER/USER)/np.pi*180\n",
    "        \n",
    "        # 동영상 각도 / 유저 각도 체크해보는 print\n",
    "#         print(angleREAL)\n",
    "#         print(angleUSER)\n",
    "#         print()\n",
    "\n",
    "        if angleUSER <= angleREAL + 40.0 and angleUSER >= angleREAL - 40.0:\n",
    "            total_point+=1\n",
    "            frame_point+=1\n",
    "        elif (angleREAL + 40.0 < angleUSER and angleUSER <= angleREAL + 60.0) and (angleUSER >= angleREAL - 60.0 and angleREAL - 40.0 > angleUSER):\n",
    "            total_point+=0.5\n",
    "            frame_point+=0.5\n",
    "            joint_counter[joint_index] += 1\n",
    "#             print(\"0.5!\")\n",
    "        else:\n",
    "            joint_counter[joint_index] += 1\n",
    "#             print(\"x\")\n",
    "        \n",
    "        joint_index += 1\n",
    "        \n",
    "        \n",
    "    if(frame_point == 8):\n",
    "        # 정확도 측정 요소 8개 모두 맞았을 때\n",
    "        \n",
    "        if(time_counter >= 20):\n",
    "            # 20 프레임 이상 연속해서 틀리다가 다시 맞게 추었을 때\n",
    "            timestamp_min_frame_num = n\n",
    "                \n",
    "            # 두 영상의 fps를 맞춰서 같은 변수로 저장했으므로 그대로 사용해도 된다.(가정)\n",
    "            \n",
    "            # 방금까지 측정된 부분의 시간(시작점)\n",
    "            timestamp_min_time_sec = (int)(timestamp_min_frame_num / fps)\n",
    "            timestamp_min_time_msec = (float)((timestamp_min_frame_num % fps)/fps)\n",
    "            timestamp_min_time = (float)(timestamp_min_time_sec) + timestamp_min_time_msec\n",
    "            timestamp_min_time_floor = math.floor(timestamp_min_time)\n",
    "                \n",
    "            # 방금까지 측정된 부분의 시간(종료지점)\n",
    "            timestamp_max_time_sec = (int)(timestamp_max_frame_num / fps)\n",
    "            timestamp_max_time_msec = (float)((timestamp_max_frame_num % fps)/fps)\n",
    "            timestamp_max_time = (float)(timestamp_max_time_sec) + timestamp_max_time_msec\n",
    "            timestamp_max_time_ceil = math.ceil(timestamp_max_time)\n",
    "            \n",
    "            # 관절 좌표 어느부분(2부위)이 많이 틀렸는지 체크해서 알려주기\n",
    "            joint_counter_sort = np.sort(joint_counter)[::-1]\n",
    "            jointstamp_temp = \"\"\n",
    "            \n",
    "            already_check = -1\n",
    "            i = 0\n",
    "            while True:\n",
    "                for j in range(0,8):\n",
    "                    if(joint_counter[j] == joint_counter_sort[i]):\n",
    "                        if((j == 0 or j == 5) and already_check != 0):\n",
    "                            jointstamp_temp = \"왼쪽 팔\"\n",
    "                            already_check = 0\n",
    "                            break\n",
    "                        elif((j == 1 or j == 4) and already_check != 1):\n",
    "                            jointstamp_temp = \"오른쪽 팔\"\n",
    "                            already_check = 1\n",
    "                            break\n",
    "                        elif((j == 2 or j == 7) and already_check != 2):\n",
    "                            jointstamp_temp = \"왼쪽 다리\"\n",
    "                            already_check = 2\n",
    "                            break\n",
    "                        elif((j == 3 or j == 6) and already_check != 3):\n",
    "                            jointstamp_temp = \"오른쪽 다리\"\n",
    "                            already_check = 3\n",
    "                            break\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "                            \n",
    "                if(i == 0):\n",
    "                    jointstamp = jointstamp_temp\n",
    "                if(i != 0 and jointstamp != jointstamp_temp):\n",
    "                    jointstamp = jointstamp + \", \"+ jointstamp_temp\n",
    "                    break\n",
    "                if(i == 7):\n",
    "                    break\n",
    "                    \n",
    "                i += 1\n",
    "                \n",
    "            # 텍스트 파일에 틀린 시간 적어줌\n",
    "            timestamp = \"대략 \" + str(timestamp_min_time_floor) + \"초 ~ \" + str(timestamp_max_time_ceil) + \"초 : \"\n",
    "            comment = timestamp + jointstamp + \" 부분을 잘 보세요.\"\n",
    "            txt.write(comment)\n",
    "            txt.write(\"\\n\")\n",
    "            \n",
    "#             print(\"wrong -> correct min\")\n",
    "#             print(n)\n",
    "                \n",
    "        # 초기화\n",
    "#         print(\"min\")\n",
    "#         print(n)\n",
    "        time_counter = 0\n",
    "        joint_counter[:] = 0\n",
    "    else:\n",
    "        # 정확도 측정 요소 8개 중 하나라도 틀렸다면\n",
    "        \n",
    "        if(time_counter == 0):\n",
    "            # 틀린 자세 처음 count\n",
    "            timestamp_max_frame_num = n\n",
    "            \n",
    "#             print(\"max\")\n",
    "#             print(n)\n",
    "        time_counter += 1\n",
    "    \n",
    "    if(n == b - length and time_counter >= 20):\n",
    "        # 마지막 프레임이면서 20 프레임 이상 연속해서 틀리다가 다시 맞게 추었을 때\n",
    "        timestamp_min_frame_num = n\n",
    "                \n",
    "        # 두 영상의 fps를 맞춰서 같은 변수로 저장했으므로 그대로 사용해도 된다.(가정)\n",
    "        \n",
    "        # 방금까지 측정된 부분의 시간(시작점)\n",
    "        timestamp_min_time_sec = (int)(timestamp_min_frame_num / fps)\n",
    "        timestamp_min_time_msec = (float)((timestamp_min_frame_num % fps)/fps)\n",
    "        timestamp_min_time = (float)(timestamp_min_time_sec) + timestamp_min_time_msec\n",
    "        timestamp_min_time_floor = math.floor(timestamp_min_time)\n",
    "                \n",
    "        # 방금까지 측정된 부분의 시간(종료지점)\n",
    "        timestamp_max_time_sec = (int)(timestamp_max_frame_num / fps)\n",
    "        timestamp_max_time_msec = (float)((timestamp_max_frame_num % fps)/fps)\n",
    "        timestamp_max_time = (float)(timestamp_max_time_sec) + timestamp_max_time_msec\n",
    "        timestamp_max_time_ceil = math.ceil(timestamp_max_time)\n",
    "                \n",
    "        # 관절 좌표 어느부분(2부위)이 많이 틀렸는지 체크해서 알려주기\n",
    "        joint_counter_sort = np.sort(joint_counter)[::-1]\n",
    "        jointstamp_temp = \"\"\n",
    "            \n",
    "        already_check = -1\n",
    "        i = 0\n",
    "        while True:\n",
    "            for j in range(0,8):\n",
    "                if(joint_counter[j] == joint_counter_sort[i]):\n",
    "                    if((j == 0 or j == 5) and already_check != 0):\n",
    "                        jointstamp_temp = \"왼쪽 팔\"\n",
    "                        already_check = 0\n",
    "                        break\n",
    "                    elif((j == 1 or j == 4) and already_check != 1):\n",
    "                        jointstamp_temp = \"오른쪽 팔\"\n",
    "                        already_check = 1\n",
    "                        break\n",
    "                    elif((j == 2 or j == 7) and already_check != 2):\n",
    "                        jointstamp_temp = \"왼쪽 다리\"\n",
    "                        already_check = 2\n",
    "                        break\n",
    "                    elif((j == 3 or j == 6) and already_check != 3):\n",
    "                        jointstamp_temp = \"오른쪽 다리\"\n",
    "                        already_check = 3\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "                    \n",
    "                            \n",
    "            if(i == 0):\n",
    "                jointstamp = jointstamp_temp\n",
    "            if(i != 0 and jointstamp != jointstamp_temp):\n",
    "                jointstamp = jointstamp + \", \"+ jointstamp_temp\n",
    "                break\n",
    "            if(i == 7):\n",
    "                break\n",
    "                    \n",
    "            i += 1\n",
    "                \n",
    "        # 텍스트 파일에 틀린 시간 적어줌\n",
    "        timestamp = \"대략 \" + str(timestamp_min_time_floor) + \"초 ~ \" + str(timestamp_max_time_ceil) + \"초 : \"\n",
    "        comment = timestamp + jointstamp + \" 부분을 잘 보세요.\"\n",
    "        txt.write(comment)\n",
    "        txt.write(\"\\n\")\n",
    "            \n",
    "#         print(\"wrong -> correct min\")\n",
    "#         print(n)\n",
    "        \n",
    "txt.close()\n",
    "        \n",
    " # 8 : 비교 각도의 개수 len(result) : frame 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6445db7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "94.57236842105263\n"
     ]
    }
   ],
   "source": [
    "print(total_point)\n",
    "print((total_point / (8 * b ) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09c624",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for num, r in enumerate(result):\n",
    "    \n",
    "    for index in body_index:\n",
    "        l1 = r[index[0]]\n",
    "        l2 = r[index[1]]\n",
    "        l3 = r[index[2]]\n",
    "        \n",
    "        ll1 = l1-l2\n",
    "        ll2 = l3-l2\n",
    "        \n",
    "        innerAB = np.dot(ll1,ll2)\n",
    "        AB = np.linalg.norm(ll1) * np.linalg.norm(ll2)\n",
    "        angle = np.arccos(innerAB/AB)\n",
    "        print(angle/np.pi*180)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65def4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
